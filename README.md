# Model-Compression-And-Acceleration

Sorted out some papers related to deep neural network model compression and acceleration for easy reference. They are mainly divided into five methods:
- [Pruning](#Pruning)
- Quantization
- Knowledge Distillation
- Matrix Decomposition
- Neural Architecture Search

## Pruning

**2015**
- 2015-NIPS-[Learning both Weights and Connections for Efficient Neural Network]
